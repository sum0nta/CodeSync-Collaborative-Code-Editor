@echo off
echo üöÄ Setting up CodeSync for Production Deployment with Ollama
echo =============================================================

REM Check if we're in the right directory
if not exist "package.json" (
    echo ‚ùå Error: Please run this script from the root directory of CodeSync
    pause
    exit /b 1
)

echo üìã Prerequisites Check:
echo 1. GitHub repository with your code ‚úì
echo 2. Vercel account (free) - https://vercel.com
echo 3. Railway account (free) - https://railway.app
echo 4. MongoDB Atlas account (free) - https://mongodb.com/cloud/atlas
echo 5. No API keys needed - Ollama is completely free! üéâ

echo.
echo üîß Configuration Steps:
echo.

echo Step 1: Update vercel.json with your Railway backend URL
echo    - Replace 'your-railway-backend-url.railway.app' with your actual Railway URL
echo.

echo Step 2: Set up Railway environment variables:
echo    NODE_ENV=production
echo    MONGODB_URI=your-mongodb-connection-string
echo    JWT_SECRET=your-super-secret-jwt-key
echo    AI_PROVIDER=ollama
echo    OLLAMA_BASE_URL=http://localhost:11434
echo    OLLAMA_MODEL=codellama:7b
echo    ALLOWED_ORIGINS=https://your-vercel-app.vercel.app
echo.

echo Step 3: Set up Vercel environment variables:
echo    REACT_APP_API_URL=your-railway-backend-url.railway.app
echo.

echo üìÅ Files Created:
echo    ‚úì vercel.json - Vercel configuration
echo    ‚úì railway.json - Railway configuration
echo    ‚úì backend/railway.toml - Backend Railway config
echo    ‚úì backend/Dockerfile - Docker configuration with Ollama
echo    ‚úì backend/.dockerignore - Docker optimization
echo    ‚úì backend/env.production - Production environment template
echo    ‚úì backend/services/aiService.production.js - Production AI service with Ollama
echo    ‚úì VERCEL_DEPLOYMENT_GUIDE.md - Complete deployment guide
echo.

echo üéØ Next Steps:
echo 1. Push your code to GitHub
echo 2. Deploy backend to Railway (will auto-detect Dockerfile)
echo 3. Deploy frontend to Vercel
echo 4. Update configuration files with your URLs
echo 5. Test your deployed application
echo.

echo üìö For detailed instructions, see: VERCEL_DEPLOYMENT_GUIDE.md
echo.

echo üéâ Benefits of Ollama on Railway:
echo - Completely free AI (no API costs)
echo - No rate limits or usage quotas
echo - Runs locally on Railway
echo - Supports multiple AI models
echo.

echo ‚ö†Ô∏è  Important Notes:
echo - First deployment takes longer (downloads ~4GB Ollama model)
echo - Railway supports Docker and long-running processes
echo - Free tier has usage limits (see guide for details)
echo.

echo üöÄ Ready to deploy with free AI! Good luck!
pause
